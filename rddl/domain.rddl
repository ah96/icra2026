// ICRA 2026 RDDL domain: situationâ†’response with explanation shaping and delivery
// -----------------------------------------------------------------------------
// How to run prost
// ./run-server.py -b ./icra2026/
// ./prost.py icra2026_instance "[Prost -s 1 -se [IPC2014]]"
// -----------------------------------------------------------------------------

domain icra2026 {

    // ===== Types =====    
    types {
        human: object;
        robot: object;
        book: object;
        waypoint: object;
        situation  : object;       // normal_success, agent_error, uncertainty, inability, suboptimal, norm_violation, unforeseen
        response_type : object;    // apology, why_expl, what_expl, next_action, ask_for_help, continue
    };


    // ===== Parameters & Variables =====
    pvariables {

        // ---------- World topology ----------
        connected(waypoint, waypoint): { non-fluent, bool, default = false };  // undirected edges should be listed both ways in the instance    

        // ---------- Task state (navigation & manipulation) ----------
        robot_at(robot, waypoint): { state-fluent, bool, default = false };
        book_at(book, waypoint): { state-fluent, bool, default = false };
        human_at(human, waypoint): { non-fluent, bool, default = false };
        holding(robot, book): { state-fluent, bool, default = false };
        delivered(book, human): { state-fluent, bool, default = false }; // whether book has been delivered to human

        // ---------- Situation --> Response core ----------
        // One-hot flag indicating the currently active situation for a (robot,human)
        is_situation(robot, human, situation): { non-fluent, bool, default = false };

        // Prior over response types for each situation (from user study)
        p_resp(response_type, situation): { non-fluent, real, default = 0.5 };

        // Which response type is selected for a (robot,human,situation); persists until changed
        selected_response(response_type, robot, human, situation): { state-fluent, bool, default = false };

        // Action to respond with a given type in the current situation (one per step)
        respond(response_type, robot, human, situation): { action-fluent, bool, default = false };

        // Helper: which response types are "explanations" (set in instance; e.g., why_expl/what_expl = true)
        is_explanation_type(response_type): { non-fluent, bool, default = false };

        // ---------- Explanation planning pipeline ----------
        explanation_planning_started(robot, human, book): { state-fluent, bool, default = false };
        explanation_planning_ended(robot, human, book): { state-fluent, bool, default = false };
        explained(robot, human, book): { state-fluent, bool, default = false }; // becomes true after explain()

        // Attribute families: modality, scope, detail, duration, tone, justification
        // Per-human baselines (probabilities of the FIRST value in each family; complement is the other value)
        visual_modality_prob(human): { non-fluent, real, default = 0.5 };   // textual = 1 - this
        local_scope_prob(human): { non-fluent, real, default = 0.5 };       // global = 1 - this
        summary_detail_prob(human): { non-fluent, real, default = 0.5 };    // narrative = 1 - this
        short_duration_prob(human): { non-fluent, real, default = 0.5 };    // long = 1 - this
        justification_contrastive_prob(human): { non-fluent, real, default = 0.5 }; // standard = 1 - this

        // Normative priors conditioned on response type (probability of FIRST value in family)
        p_visual_given_rt(response_type): { non-fluent, real, default = 0.5 };
        p_local_scope_given_rt(response_type): { non-fluent, real, default = 0.5 };
        p_summary_detail_given_rt(response_type): { non-fluent, real, default = 0.5 };
        p_short_duration_given_rt(response_type): { non-fluent, real, default = 0.5 };
        p_just_contrastive_given_rt(response_type): { non-fluent, real, default = 0.5 };

        // Mixing weights between baselines and response-type norms
        alpha_modality: { non-fluent, real, default = 0.5 };
        alpha_scope: { non-fluent, real, default = 0.5 };
        alpha_detail: { non-fluent, real, default = 0.5 };
        alpha_duration: { non-fluent, real, default = 0.5 };
        alpha_justification: { non-fluent, real, default = 0.5 };

        // Wanted samples per human (stochastic preferences drawn each step)
        modality_visual_wanted(human): { state-fluent, bool, default = false }; // textual_wanted = !visual_wanted
        scope_local_wanted(human): { state-fluent, bool, default = false };     // global_wanted = !local_wanted
        detail_summary_wanted(human): { state-fluent, bool, default = false };  // narrative_wanted = !summary_wanted
        duration_short_wantagent_errored(human): { state-fluent, bool, default = false };  // long_wanted = !short_wanted
        justification_contrastive_wanted(human): { state-fluent, bool, default = false }; // standard_wanted = !contrastive_wanted

        // Chosen attribute values (persist for a (robot,human,book))
        modality_visual_selected(robot, human, book): { state-fluent, bool, default = false };
        modality_textual_selected(robot, human, book): { state-fluent, bool, default = false };

        scope_local_selected(robot, human, book): { state-fluent, bool, default = false };
        scope_global_selected(robot, human, book): { state-fluent, bool, default = false };

        detail_summary_selected(robot, human, book): { state-fluent, bool, default = false };
        detail_narrative_selected(robot, human, book): { state-fluent, bool, default = false };

        duration_short_selected(robot, human, book): { state-fluent, bool, default = false };
        duration_long_selected(robot, human, book): { state-fluent, bool, default = false };

        justification_standard_selected(robot, human, book): { state-fluent, bool, default = false };
        justification_contrastive_selected(robot, human, book): { state-fluent, bool, default = false };


        // ---------- Actions ----------
        // Navigation & manipulation
        goto_waypoint(robot, waypoint, waypoint): { action-fluent, bool, default = false };
        pick_book(robot, book): { action-fluent, bool, default = false };
        drop_book(robot, book): { action-fluent, bool, default = false };

        // Explanation planning
        start_explanation_planning(robot, human, book): { action-fluent, bool, default = false };
        end_explanation_planning(robot, human, book): { action-fluent, bool, default = false };
        explain(robot, human, book): { action-fluent, bool, default = false };

        // Attribute selections
        choose_visual_modality(robot, human, book): { action-fluent, bool, default = false };
        choose_textual_modality(robot, human, book): { action-fluent, bool, default = false };

        choose_local_scope(robot, human, book): { action-fluent, bool, default = false };
        choose_global_scope(robot, human, book): { action-fluent, bool, default = false };

        choose_summary_detail(robot, human, book): { action-fluent, bool, default = false };
        choose_narrative_detail(robot, human, book): { action-fluent, bool, default = false };

        choose_short_duration(robot, human, book): { action-fluent, bool, default = false };
        choose_long_duration(robot, human, book): { action-fluent, bool, default = false };

        choose_justification_standard(robot, human, book): { action-fluent, bool, default = false };
        choose_justification_contrastive(robot, human, book): { action-fluent, bool, default = false };

        // Delivery (two variants: with/without explanation)
        deliver_book(robot, book, human): { action-fluent, bool, default = false };
        deliver_book_without_explanation(robot, book, human): { action-fluent, bool, default = false };


        // ---------- Reward weights / costs (override in instance as needed) ----------
        w_deliver_explained: { non-fluent, real, default = 6.0 };
        w_deliver_unexplained: { non-fluent, real, default = 3.0 };
        w_resp_match: { non-fluent, real, default = 1.0 };
        w_modality_match: { non-fluent, real, default = 0.5 };
        w_scope_match: { non-fluent, real, default = 0.5 };
        w_detail_match: { non-fluent, real, default = 0.5 };
        w_duration_match: { non-fluent, real, default = 0.3 };
        w_justification_match: { non-fluent, real, default = 0.3 };
        w_consistency: { non-fluent, real, default = 0.2 }; // bonus for keeping attribute choices consistent across steps

        c_move: { non-fluent, real, default = 0.4 };
        c_pickdrop: { non-fluent, real, default = 0.1 };
        c_explain_base: { non-fluent, real, default = 0.3 };
        c_long: { non-fluent, real, default = 0.2 };
        c_narrative: { non-fluent, real, default = 0.2 };
        c_switch_attr: { non-fluent, real, default = 0.1 }; // penalty for changing attribute family choices from previous step
        c_step: { non-fluent, real, default = 0.02 }; // small time penalty per step
    
    };


    // ===== Dynamics =====
    cpfs {

        // --- Navigation dynamics (single-step move)
        robot_at'(?r, ?w) = if (exists_{?w1: waypoint} (goto_waypoint(?r, ?w1, ?w))) then true 
                            else if (exists_{?w1: waypoint} (goto_waypoint(?r, ?w, ?w1))) then false
                            else robot_at(?r, ?w);

        // --- Book movement
        book_at'(?bk, ?w) =
            // if picked at (r,w) it disappears from waypoint; if dropped at (r,w) it appears
            ( book_at(?bk, ?w) & ~exists_{?r: robot} [ pick_book(?r, ?bk) & robot_at(?r, ?w) ] )
            | exists_{?r: robot} [ drop_book(?r, ?bk) & robot_at(?r, ?w) ];

        // --- Pick/drop/deliver dynamics ---
        holding'(?r, ?bk) = ( holding(?r, ?bk)
            & ~drop_book(?r, ?bk)
            & ~exists_{?h: human} [
                    deliver_book(?r, ?bk, ?h) | deliver_book_without_explanation(?r, ?bk, ?h)
                ] )
        | pick_book(?r, ?bk);

        // --- Book delivered
        delivered'(?bk, ?h) = delivered(?bk, ?h) | deliver_book(?r, ?bk, ?h);

        // --- Response selection persistence/update
        selected_response'(?rt, ?r, ?h, ?s) =
            respond(?rt, ?r, ?h, ?s)
            | ( selected_response(?rt, ?r, ?h, ?s)
                & ~exists_{?rt2: response_type} [ respond(?rt2, ?r, ?h, ?s) ] );

        // --- Explanation pipeline persistence
        explanation_planning_started'(?r, ?h, ?b) = explanation_planning_started(?r, ?h, ?b) | start_explanation_planning(?r, ?h, ?b);
        explanation_planning_ended'(?r, ?h, ?b) = explanation_planning_ended(?r, ?h, ?b) | end_explanation_planning(?r, ?h, ?b);
        explained'(?r, ?h, ?b) = explained(?r, ?h, ?b) | explain(?r, ?h, ?b);

        // --- Wanted preferences (mixture of per-human baselines and response-type norms, weighted by situation) ---
        modality_visual_wanted'(?h) = Bernoulli(
            (1 - alpha_modality) * visual_modality_prob(?h)
          + alpha_modality * ( sum_{?rb: robot, ?s: situation} [
                if ( is_situation(?rb, ?h, ?s) ) then ( sum_{?rt: response_type} [ p_resp(?rt, ?s) * p_visual_given_rt(?rt) ] ) else 0
            ] )
        );
        scope_local_wanted'(?h) = Bernoulli(
            (1 - alpha_scope) * local_scope_prob(?h)
          + alpha_scope * ( sum_{?rb: robot, ?s: situation} [
                if ( is_situation(?rb, ?h, ?s) ) then ( sum_{?rt: response_type} [ p_resp(?rt, ?s) * p_local_scope_given_rt(?rt) ] ) else 0
            ] )
        );
        detail_summary_wanted'(?h) = Bernoulli(
            (1 - alpha_detail) * summary_detail_prob(?h)
          + alpha_detail * ( sum_{?rb: robot, ?s: situation} [
                if ( is_situation(?rb, ?h, ?s) ) then ( sum_{?rt: response_type} [ p_resp(?rt, ?s) * p_summary_detail_given_rt(?rt) ] ) else 0
            ] )
        );
        duration_short_wanted'(?h) = Bernoulli(
            (1 - alpha_duration) * short_duration_prob(?h)
          + alpha_duration * ( sum_{?rb: robot, ?s: situation} [
                if ( is_situation(?rb, ?h, ?s) ) then ( sum_{?rt: response_type} [ p_resp(?rt, ?s) * p_short_duration_given_rt(?rt) ] ) else 0
            ] )
        );
        justification_contrastive_wanted'(?h) = Bernoulli(
            (1 - alpha_justification) * justification_contrastive_prob(?h)
          + alpha_justification * ( sum_{?rb: robot, ?s: situation} [
                if ( is_situation(?rb, ?h, ?s) ) then ( sum_{?rt: response_type} [ p_resp(?rt, ?s) * p_just_contrastive_given_rt(?rt) ] ) else 0
            ] )
        );

        // --- Attribute selection persistence/update (mutual exclusivity within families)
        modality_visual_selected'(?r, ?h, ?b) =
            choose_visual_modality(?r, ?h, ?b) | (modality_visual_selected(?r, ?h, ?b) & ~choose_textual_modality(?r, ?h, ?b));
        modality_textual_selected'(?r, ?h, ?b) =
            choose_textual_modality(?r, ?h, ?b) | (modality_textual_selected(?r, ?h, ?b) & ~choose_visual_modality(?r, ?h, ?b));

        scope_local_selected'(?r, ?h, ?b) =
            choose_local_scope(?r, ?h, ?b) | (scope_local_selected(?r, ?h, ?b) & ~choose_global_scope(?r, ?h, ?b));
        scope_global_selected'(?r, ?h, ?b) =
            choose_global_scope(?r, ?h, ?b) | (scope_global_selected(?r, ?h, ?b) & ~choose_local_scope(?r, ?h, ?b));

        detail_summary_selected'(?r, ?h, ?b) =
            choose_summary_detail(?r, ?h, ?b) | (detail_summary_selected(?r, ?h, ?b) & ~choose_narrative_detail(?r, ?h, ?b));
        detail_narrative_selected'(?r, ?h, ?b) =
            choose_narrative_detail(?r, ?h, ?b) | (detail_narrative_selected(?r, ?h, ?b) & ~choose_summary_detail(?r, ?h, ?b));

        duration_short_selected'(?r, ?h, ?b) =
            choose_short_duration(?r, ?h, ?b) | (duration_short_selected(?r, ?h, ?b) & ~choose_long_duration(?r, ?h, ?b));
        duration_long_selected'(?r, ?h, ?b) =
            choose_long_duration(?r, ?h, ?b) | (duration_long_selected(?r, ?h, ?b) & ~choose_short_duration(?r, ?h, ?b));

        justification_standard_selected'(?r, ?h, ?b) =
            choose_justification_standard(?r, ?h, ?b) | (justification_standard_selected(?r, ?h, ?b) & ~choose_justification_contrastive(?r, ?h, ?b));
        justification_contrastive_selected'(?r, ?h, ?b) =
            choose_justification_contrastive(?r, ?h, ?b) | (justification_contrastive_selected(?r, ?h, ?b) & ~choose_justification_standard(?r, ?h, ?b));        

    }


    // ===== Action Preconditions (guards & exclusivity) =====
    action-preconditions {

        // --- Movement constraints
        // A robot must be in a position to move to another
        forall_{?r: robot, ?wf: waypoint, ?wt: waypoint} [goto_waypoint(?r, ?wf, ?wt) => ( ~goal_reached ^ robot_at(?r, ?wf) ^ connected(?wf, ?wt) ^ ?wf ~= ?wt ) ];

        // A robot can not be in two places at the same time
        forall_{?r: robot, ?w1: waypoint, ?w2: waypoint} [ ?w1 == ?w2 | (robot_at(?r, ?w1) => ~robot_at(?r, ?w2)) ];        

        // --- Response selection (only for active situation; at-most-one per step)
        forall_{?rt: response_type, ?r: robot, ?h: human, ?s: situation} [
            respond(?rt, ?r, ?h, ?s) => is_situation(?r, ?h, ?s)
        ];
        forall_{?r: robot, ?h: human, ?s: situation, ?rt1: response_type, ?rt2: response_type} [
            (?rt1 ~= ?rt2) => ~( respond(?rt1, ?r, ?h, ?s) ^ respond(?rt2, ?r, ?h, ?s) )
        ];

        // --- Pick/drop constraints
        forall_{?r: robot, ?bk: book, ?w: waypoint} [
            pick_book(?r, ?bk) => ( robot_at(?r, ?w) ^ book_at(?bk, ?w) ^ ~holding(?r, ?bk) )
        ];
        forall_{?r: robot, ?bk: book, ?w: waypoint} [
            drop_book(?r, ?bk) => ( robot_at(?r, ?w) ^ holding(?r, ?bk) )
        ];

        // --- Planning sequence constraints
        forall_{?r: robot, ?h: human, ?b: book} [
            start_explanation_planning(?r, ?h, ?b) =>
            ( ~explanation_planning_started(?r, ?h, ?b) ^ ~explanation_planning_ended(?r, ?h, ?b) ^ ~explained(?r, ?h, ?b) )
        ];
        forall_{?r: robot, ?h: human, ?b: book} [
            end_explanation_planning(?r, ?h, ?b) =>
            ( explanation_planning_started(?r, ?h, ?b)
              ^ (modality_visual_selected(?r, ?h, ?b) | modality_textual_selected(?r, ?h, ?b))
              ^ (scope_local_selected(?r, ?h, ?b) | scope_global_selected(?r, ?h, ?b))
              ^ (detail_summary_selected(?r, ?h, ?b) | detail_narrative_selected(?r, ?h, ?b)) )
        ];
        forall_{?r: robot, ?h: human, ?b: book} [
            explain(?r, ?h, ?b) =>
            ( explanation_planning_ended(?r, ?h, ?b)
              ^ (modality_visual_selected(?r, ?h, ?b) | modality_textual_selected(?r, ?h, ?b))
              ^ (scope_local_selected(?r, ?h, ?b) | scope_global_selected(?r, ?h, ?b))
              ^ (detail_summary_selected(?r, ?h, ?b) | detail_narrative_selected(?r, ?h, ?b)) )
        ];

        // --- Explanation gating: attribute choices only when an explanation-type response is active in the current situation
        forall_{?rb: robot, ?h: human, ?b: book} [
            choose_visual_modality(?rb, ?h, ?b) =>
              exists_{?s: situation, ?rt: response_type} [
                  is_situation(?rb, ?h, ?s) & is_explanation_type(?rt) & (respond(?rt, ?rb, ?h, ?s) | selected_response(?rt, ?rb, ?h, ?s))
              ]
        ];
        forall_{?rb: robot, ?h: human, ?b: book} [
            choose_textual_modality(?rb, ?h, ?b) =>
              exists_{?s: situation, ?rt: response_type} [
                  is_situation(?rb, ?h, ?s) & is_explanation_type(?rt) & (respond(?rt, ?rb, ?h, ?s) | selected_response(?rt, ?rb, ?h, ?s))
              ]
        ];
        forall_{?rb: robot, ?h: human, ?b: book} [
            choose_local_scope(?rb, ?h, ?b) =>
              exists_{?s: situation, ?rt: response_type} [
                  is_situation(?rb, ?h, ?s) & is_explanation_type(?rt) & (respond(?rt, ?rb, ?h, ?s) | selected_response(?rt, ?rb, ?h, ?s))
              ]
        ];
        forall_{?rb: robot, ?h: human, ?b: book} [
            choose_global_scope(?rb, ?h, ?b) =>
              exists_{?s: situation, ?rt: response_type} [
                  is_situation(?rb, ?h, ?s) & is_explanation_type(?rt) & (respond(?rt, ?rb, ?h, ?s) | selected_response(?rt, ?rb, ?h, ?s))
              ]
        ];
        forall_{?rb: robot, ?h: human, ?b: book} [
            choose_summary_detail(?rb, ?h, ?b) =>
              exists_{?s: situation, ?rt: response_type} [
                  is_situation(?rb, ?h, ?s) & is_explanation_type(?rt) & (respond(?rt, ?rb, ?h, ?s) | selected_response(?rt, ?rb, ?h, ?s))
              ]
        ];
        forall_{?rb: robot, ?h: human, ?b: book} [
            choose_narrative_detail(?rb, ?h, ?b) =>
              exists_{?s: situation, ?rt: response_type} [
                  is_situation(?rb, ?h, ?s) & is_explanation_type(?rt) & (respond(?rt, ?rb, ?h, ?s) | selected_response(?rt, ?rb, ?h, ?s))
              ]
        ];
        forall_{?rb: robot, ?h: human, ?b: book} [
            choose_short_duration(?rb, ?h, ?b) =>
              exists_{?s: situation, ?rt: response_type} [
                  is_situation(?rb, ?h, ?s) & is_explanation_type(?rt) & (respond(?rt, ?rb, ?h, ?s) | selected_response(?rt, ?rb, ?h, ?s))
              ]
        ];
        forall_{?rb: robot, ?h: human, ?b: book} [
            choose_long_duration(?rb, ?h, ?b) =>
              exists_{?s: situation, ?rt: response_type} [
                  is_situation(?rb, ?h, ?s) & is_explanation_type(?rt) & (respond(?rt, ?rb, ?h, ?s) | selected_response(?rt, ?rb, ?h, ?s))
              ]
        ];
        forall_{?rb: robot, ?h: human, ?b: book} [
            choose_justification_standard(?rb, ?h, ?b) =>
              exists_{?s: situation, ?rt: response_type} [
                  is_situation(?rb, ?h, ?s) & is_explanation_type(?rt) & (respond(?rt, ?rb, ?h, ?s) | selected_response(?rt, ?rb, ?h, ?s))
              ]
        ];
        forall_{?rb: robot, ?h: human, ?b: book} [
            choose_justification_contrastive(?rb, ?h, ?b) =>
              exists_{?s: situation, ?rt: response_type} [
                  is_situation(?rb, ?h, ?s) & is_explanation_type(?rt) & (respond(?rt, ?rb, ?h, ?s) | selected_response(?rt, ?rb, ?h, ?s))
              ]
        ];

        // --- Attribute mutual exclusivity per step
        forall_{?rb: robot, ?h: human, ?b: book} [ ~( choose_visual_modality(?rb, ?h, ?b) ^ choose_textual_modality(?rb, ?h, ?b) ) ];
        forall_{?rb: robot, ?h: human, ?b: book} [ ~( choose_local_scope(?rb, ?h, ?b) ^ choose_global_scope(?rb, ?h, ?b) ) ];
        forall_{?rb: robot, ?h: human, ?b: book} [ ~( choose_summary_detail(?rb, ?h, ?b) ^ choose_narrative_detail(?rb, ?h, ?b) ) ];
        forall_{?rb: robot, ?h: human, ?b: book} [ ~( choose_short_duration(?rb, ?h, ?b) ^ choose_long_duration(?rb, ?h, ?b) ) ];
        forall_{?rb: robot, ?h: human, ?b: book} [ ~( choose_justification_standard(?rb, ?h, ?b) ^ choose_justification_contrastive(?rb, ?h, ?b) ) ];

        // --- Deliver constraints
        forall_{?r: robot, ?bk: book, ?h: human, ?w: waypoint} [
            deliver_book(?r, ?bk, ?h) => ( robot_at(?r, ?w) ^ human_at(?h, ?w) ^ holding(?r, ?bk) ^ explained(?r, ?h, ?bk) )
        ];
        forall_{?r: robot, ?bk: book, ?h: human, ?w: waypoint} [
            deliver_book_without_explanation(?r, ?bk, ?h) => ( robot_at(?r, ?w) ^ human_at(?h, ?w) ^ holding(?r, ?bk) ^ ~explained(?r, ?h, ?bk) )
        ];

    }

}
